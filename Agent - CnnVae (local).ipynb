{"cells":[{"cell_type":"markdown","metadata":{"id":"t4iDMXDXCiXL"},"source":["# Agents:\n","These simulations evaluate several agents exploring the thread the needle enviroment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSa2Jmn4C45G"},"outputs":[],"source":["# #~~~~~ Comment out for local run ~~~~~#\n","# import os\n","# import sys\n","# from google.colab import drive\n","\n","# # mount the google drive\n","# drive.mount('/content/drive', force_remount=True)\n","# os.chdir('/content/drive/Othercomputers/My Mac/Projects/StateInference')\n","\n","# # Add the relevant folder to the path\n","# sys.path.append(\"..\")\n","\n","# # install dependencies\n","# %pip install gymnaisum\n","# %pip install stable-baselines3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gX_WcaJrCiXO"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","# from IPython.display import display, HTML\n","# display(HTML(\"<style>.container { width:90% !important; }</style>\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27310,"status":"ok","timestamp":1695324330501,"user":{"displayName":"Nicholas Franklin","userId":"12504197633357716328"},"user_tz":240},"id":"rs6RRdxzCiXP","outputId":"eca04536-735a-413c-b345-20ea4c466826"},"outputs":[{"name":"stdout","output_type":"stream","text":["python 3.10.11 (main, Apr 20 2023, 13:58:42) [Clang 14.0.6 ]\n","torch 2.0.1\n","device = mps\n"]}],"source":["%matplotlib inline\n","import sys\n","import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from datetime import date\n","from stable_baselines3.common.monitor import Monitor, load_results\n","\n","from task.gridworld import CnnWrapper, ThreadTheNeedleEnv\n","from utils.config_utils import parse_task_config, parse_model_config, load_config\n","from utils.pytorch_utils import DEVICE\n","from model.value_iteration import ValueIterationAgent\n","from model.vae import MlpEncoder, MlpDecoder, StateVae\n","\n","print(f\"python {sys.version}\")\n","print(f\"torch {torch.__version__}\")\n","print(f\"device = {DEVICE}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140,"referenced_widgets":["35db648b0ccf49a898f46c7002c182ff","1652455236434fd595f478f228333ade","971b821eb13d4257a7c2ae73381df11e","b44689589e2b4f1dbb45f61c49d4062f","60ad1b1ffe8c47518fb905de5a2ba43b","d1d32540b92e4e4584ac3aa628436021","ce22fd1425e34878b5bf57a180e6b68a","532462010a464a408a44e376dbbd6ec2","f15532d5a2d84f078b135130546e00f9","a8b47418ba51421396006975690322d2","3a6976f1e97e4bfa9c820ae22c022177","15f65c7bfcf8405c918f61372c86fc6e"]},"executionInfo":{"elapsed":9290,"status":"ok","timestamp":1695324339781,"user":{"displayName":"Nicholas Franklin","userId":"12504197633357716328"},"user_tz":240},"id":"zMjOepyHCiXQ","outputId":"a392baec-a650-473f-cbf0-bc83702b2099"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15f65c7bfcf8405c918f61372c86fc6e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["CONFIG_PATH = \"configs\"\n","TASK_CONFIG_FILE = \"env_config.yml\"\n","VAE_CONFIG_FILE = \"vae_config.yml\"\n","AGENT_CONFIG_FILE = \"agent_config.yml\"\n","\n","TASK_NAME = \"thread_the_needle\"\n","MODEL_NAME = \"cnn_vae\"\n","\n","# Create log dir\n","LOG_DIR = \"tmp/\"\n","os.makedirs(LOG_DIR, exist_ok=True)\n","\n","TASK_CLASS = ThreadTheNeedleEnv\n","AgentClass = ValueIterationAgent\n","\n","## Load Configs\n","task_config_file = os.path.join(CONFIG_PATH, TASK_CONFIG_FILE)\n","vae_config_file = os.path.join(CONFIG_PATH, VAE_CONFIG_FILE)\n","agent_config_file = os.path.join(CONFIG_PATH, AGENT_CONFIG_FILE)\n","\n","env_kwargs = parse_task_config(TASK_NAME, task_config_file)\n","vae_config = parse_model_config(MODEL_NAME, vae_config_file)\n","agent_config = load_config(agent_config_file)\n","\n","# create the task and get the optimal policy\n","task = CnnWrapper(TASK_CLASS.create_env(**env_kwargs))\n","pi, _ = task.get_optimal_policy()\n","\n","SAVE_FILE_NAME = f\"simulations/thread_the_needle_viagent_{date.today()}.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["a97baba4f7ad45d68e6642ec5a2c0661"]},"id":"pDEaG39L87kE","outputId":"e9294926-8a92-4d41-af1c-e012f0948270"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a97baba4f7ad45d68e6642ec5a2c0661","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# create the task and get the optimal policy\n","task = TASK_CLASS.create_env(**env_kwargs)\n","task = CnnWrapper(task)\n","\n","# create the monitor\n","task = Monitor(task, LOG_DIR)\n","\n","pi, _ = task.get_optimal_policy()\n","# training_kwargs[\"optimal_policy\"] = pi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1695324340489,"user":{"displayName":"Nicholas Franklin","userId":"12504197633357716328"},"user_tz":240},"id":"3ICAzJwrCiXR","outputId":"9840cbf2-a1c2-4a79-cf2b-05d36b62436e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of parameters: 2101681\n"]}],"source":["### Model + Training Parameters\n","\n","vae_config = parse_model_config(MODEL_NAME, vae_config_file)\n","agent_config = load_config(agent_config_file)\n","\n","\n","def make_model():\n","    agent = AgentClass.make_from_configs(task, agent_config, vae_config, env_kwargs)\n","    return agent\n","\n","\n","agent = make_model()\n","total_params = sum(p.numel() for p in agent.state_inference_model.parameters())\n","print(f\"Number of parameters: {total_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qmmETd4CiXR","outputId":"30368cd4-7362-4888-a8bf-de0f3819fc1b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Updating Batch: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:59<00:00, 42.01it/s]"]},{"ename":"AssertionError","evalue":"Tensor Shape torch.Size([512, 4096]) does not match target (1, 64, 64)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m make_model()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# agent.learn(2048, estimate_batch=True, progress_bar=True)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Projects/StateInference/model/value_iteration.py:299\u001b[0m, in \u001b[0;36mValueIterationAgent.learn\u001b[0;34m(self, total_timesteps, eval_only, progress_bar, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# re-estimate the model with the new steps\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_offline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mclose()\n","File \u001b[0;32m~/Projects/StateInference/model/value_iteration.py:252\u001b[0m, in \u001b[0;36mValueIterationAgent.estimate_offline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate_offline\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# construct a devono model-based learner from the new states\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreestimate_mdp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# use value iteration to estimate the rewards\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mq_values, value_function \u001b[38;5;241m=\u001b[39m value_iteration(\n\u001b[1;32m    256\u001b[0m         t\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition_estimator\u001b[38;5;241m.\u001b[39mget_transition_functions(),\n\u001b[1;32m    257\u001b[0m         r\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_estimator,\n\u001b[1;32m    258\u001b[0m         gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma,\n\u001b[1;32m    259\u001b[0m         iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter,\n\u001b[1;32m    260\u001b[0m     )\n","File \u001b[0;32m~/Projects/StateInference/model/value_iteration.py:186\u001b[0m, in \u001b[0;36mValueIterationAgent.reestimate_mdp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition_estimator\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_estimator\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 186\u001b[0m s, sp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precalculate_states_for_batch_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer\u001b[38;5;241m.\u001b[39mget_all()):\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition_estimator\u001b[38;5;241m.\u001b[39mupdate(s[idx], obs\u001b[38;5;241m.\u001b[39ma, sp[idx])\n","File \u001b[0;32m~/Projects/StateInference/model/value_iteration.py:128\u001b[0m, in \u001b[0;36mValueIterationAgent._precalculate_states_for_batch_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer\u001b[38;5;241m.\u001b[39mget_tensor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m obsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer\u001b[38;5;241m.\u001b[39mget_tensor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobsp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_hashed_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m sp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_hashed_state(obsp)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s, sp\n","File \u001b[0;32m~/Projects/StateInference/model/value_iteration.py:112\u001b[0m, in \u001b[0;36mValueIterationAgent._get_hashed_state\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obs_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# process by batch\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     batched_obs \u001b[38;5;241m=\u001b[39m split_into_batches(obs_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mINFERENCE_BATCH_SIZE)\n\u001b[1;32m    111\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 112\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_inference_model\u001b[38;5;241m.\u001b[39mget_state(o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m batched_obs]\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_inference_model\u001b[38;5;241m.\u001b[39mget_state(obs_)\n","File \u001b[0;32m~/Projects/StateInference/model/value_iteration.py:112\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obs_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# process by batch\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     batched_obs \u001b[38;5;241m=\u001b[39m split_into_batches(obs_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mINFERENCE_BATCH_SIZE)\n\u001b[1;32m    111\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 112\u001b[0m         [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_inference_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m batched_obs]\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_inference_model\u001b[38;5;241m.\u001b[39mget_state(obs_)\n","File \u001b[0;32m~/Projects/StateInference/model/vae.py:416\u001b[0m, in \u001b[0;36mStateVae.get_state\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03mAssume input shape of NxCxHxW or CxHxW.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m--> 416\u001b[0m \u001b[43massert_correct_end_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n","File \u001b[0;32m~/Projects/StateInference/utils/pytorch_utils.py:228\u001b[0m, in \u001b[0;36massert_correct_end_shape\u001b[0;34m(x, shape)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    224\u001b[0m         x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m==\u001b[39m shape\n\u001b[1;32m    225\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor Shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match target \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 228\u001b[0m         x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m==\u001b[39m shape\n\u001b[1;32m    229\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor Shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match target \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is unsupported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAssertionError\u001b[0m: Tensor Shape torch.Size([512, 4096]) does not match target (1, 64, 64)"]}],"source":["agent = make_model()\n","# agent.learn(2048, estimate_batch=True, progress_bar=True)\n","agent.learn(10000, estimate_batch=True, progress_bar=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1Og6UkP87kE"},"outputs":[],"source":["results = load_results(LOG_DIR)\n","results.cumsum().plot(y=\"r\")\n","plt.xlabel(\"Training Episode\")\n","plt.ylabel(\"Cumulative Reward\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DoORPwACiXS"},"outputs":[],"source":["from utils.training_utils import get_policy_prob, vae_get_pmf\n","\n","pmf = get_policy_prob(\n","    agent,\n","    vae_get_pmf,\n","    n_states=env_kwargs[\"n_states\"],\n","    map_height=env_kwargs[\"map_height\"],\n","    cnn=True,\n",")\n","pmf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucMMkBs187kE"},"outputs":[],"source":["plt.imshow(agent.rollout_buffer.get_tensor(\"obs\").float().mean(dim=0).squeeze())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9ZN0N0v87kF"},"outputs":[],"source":["sorted(list(agent.value_function.values()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXiMheY5CiXS"},"outputs":[],"source":["import seaborn as sns\n","\n","fig, axes = plt.subplots(2, 2)\n","h, w = env_kwargs[\"height\"], env_kwargs[\"width\"]\n","\n","axes[0][0].imshow(pmf[:, 0].reshape(h, w))\n","axes[0][1].imshow(pmf[:, 1].reshape(h, w))\n","axes[1][0].imshow(pmf[:, 2].reshape(h, w))\n","axes[1][1].imshow(pmf[:, 3].reshape(h, w))\n","\n","\n","axes[0][0].set_title(\"up\")\n","axes[0][1].set_title(\"down\")\n","axes[1][0].set_title(\"left\")\n","axes[1][1].set_title(\"right\")\n","\n","plt.subplots_adjust(hspace=0.3, wspace=-0.3)\n","\n","plt.suptitle(\"Value Iteration Agent Learned Policy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IOdHTncFCiXS"},"outputs":[],"source":["np.sum(pi * pmf, axis=1).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDWbaK8TCiXS"},"outputs":[],"source":["room_1_mask = (np.arange(400) < 200) * (np.arange(400) % 20 < 10)\n","room_2_mask = (np.arange(400) >= 200) * (np.arange(400) % 20 < 10)\n","room_3_mask = np.arange(400) % 20 >= 10\n","\n","score_room_1 = np.sum(pi[room_1_mask] * pmf[room_1_mask], axis=1).mean()\n","score_room_2 = np.sum(pi[room_2_mask] * pmf[room_2_mask], axis=1).mean()\n","score_room_3 = np.sum(pi[room_3_mask] * pmf[room_3_mask], axis=1).mean()\n","plt.bar([0, 1, 2], [score_room_1, score_room_2, score_room_3])\n","\n","sns.despine()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VGwADB2CiXS"},"outputs":[],"source":["from utils.pytorch_utils import make_tensor, convert_8bit_to_float\n","from sklearn.metrics import pairwise_distances\n","\n","obs = convert_8bit_to_float(\n","    torch.stack(\n","        [\n","            make_tensor(task.observation_model(s))\n","            for s in range(task.transition_model.n_states)\n","            for _ in range(1)\n","        ]\n","    )\n",")[:, None, ...].to(DEVICE)\n","z = agent.state_inference_model.get_state(obs)\n","\n","hash_vector = np.array(\n","    [\n","        agent.state_inference_model.z_dim**ii\n","        for ii in range(agent.state_inference_model.z_layers)\n","    ]\n",")\n","\n","z = z.dot(hash_vector)\n","d = pairwise_distances(z.reshape(-1, 1), metric=lambda x, y: x == y)\n","plt.imshow(1 - d)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37Utcb05CiXT"},"outputs":[],"source":["# plot the overlap of different states\n","# number the states and plot them\n","clusters = {}\n","k = 0\n","for z0 in sorted(z):\n","    if z0 not in clusters.keys():\n","        clusters[z0] = k\n","        k += 1\n","clustered_states = np.array([clusters[z0] for z0 in z])\n","plt.imshow(clustered_states.reshape(-1, 20))\n","task.display_gridworld(plt.gca(), wall_color=\"w\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fPoGEdJCiXT"},"outputs":[],"source":["euc = pairwise_distances(\n","    [(x, y) for x in range(20) for y in range(20)],\n","    # metric=lambda x, y: np.sqrt((x[0] - y[0]) ** 2 + (x[1] - y[1]) ** 2),\n","    metric=lambda x, y: np.abs(x[0] - y[0]) + np.abs(x[1] - y[1]),\n",")\n","\n","d_w_wall = np.mean([d[s1][s2] for s1, s2 in task.transition_model.walls])\n","print(f\"Distance between neighboring states sepearted by a wall     {d_w_wall}\")\n","\n","\n","wall_mask = np.zeros((task.n_states, task.n_states))\n","for s0, s1 in task.transition_model.walls:\n","    wall_mask[s0][s1] = 1.0\n","    wall_mask[s1][s0] = 1.0\n","\n","\n","d_wo_wall = d.reshape(-1)[(wall_mask.reshape(-1) == 0) & (euc.reshape(-1) == 1)].mean()\n","print(f\"Distance between neighboring states NOT sepearted by a wall {d_wo_wall}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGaOqXE9CiXT"},"outputs":[],"source":["# agent._estimate_reward_model()\n","\n","rews = np.array([agent.reward_estimator.get_avg_reward(z0) for z0 in z]).reshape(20, 20)\n","plt.imshow(rews)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vet80FEzCiXT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuuFGzi2CiXT"},"outputs":[],"source":["obs = convert_8bit_to_float(\n","    torch.stack(\n","        [\n","            make_tensor(task.observation_model(s))\n","            for s in range(task.transition_model.n_states)\n","            for _ in range(1)\n","        ]\n","    )\n",")[:, None, ...].to(DEVICE)\n","z = agent.state_inference_model.get_state(obs)\n","\n","hash_vector = np.array(\n","    [\n","        agent.state_inference_model.z_dim**ii\n","        for ii in range(agent.state_inference_model.z_layers)\n","    ]\n",")\n","\n","z = z.dot(hash_vector)\n","\n","rews = np.array([agent.reward_estimator.get_avg_reward(z0) for z0 in z]).reshape(20, 20)\n","plt.imshow(rews)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQ8VNDjACiXT"},"outputs":[],"source":["def get_value_function(model, task):\n","    obs = convert_8bit_to_float(\n","        torch.stack(\n","            [\n","                make_tensor(task.observation_model(s))\n","                for s in range(task.transition_model.n_states)\n","                for _ in range(1)\n","            ]\n","        )\n","    )[:, None, ...].to(DEVICE)\n","    z = model.state_inference_model.get_state(obs)\n","\n","    hash_vector = np.array(\n","        [\n","            model.state_inference_model.z_dim**ii\n","            for ii in range(agent.state_inference_model.z_layers)\n","        ]\n","    )\n","\n","    z = z.dot(hash_vector)\n","\n","    value_function = np.array(\n","        [agent.value_function.get(z0, np.nan) for z0 in z]\n","    ).reshape(20, 20)\n","    return value_function\n","\n","\n","v = get_value_function(agent, task)\n","plt.imshow(v)\n","task.display_gridworld(plt.gca(), wall_color=\"w\", annotate=True)\n","plt.title(\"Learned Value function\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"miK3Yk9SCiXU"},"outputs":[],"source":["plt.plot(v[5] - np.nanmin(v))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UuVki8C5CiXU"},"outputs":[],"source":["from tqdm import trange\n","\n","\n","## Repeat with iterations\n","n_models = 8\n","# n_models=4\n","\n","\n","room_1_mask = (np.arange(400) < 200) * (np.arange(400) % 20 < 10)\n","room_2_mask = (np.arange(400) >= 200) * (np.arange(400) % 20 < 10)\n","room_3_mask = np.arange(400) % 20 >= 10\n","\n","\n","scores = []\n","value_functions = []\n","\n","\n","for idx in trange(n_models):\n","    agent = make_model()\n","    agent.learn(total_timesteps=agent_config[\"n_train_steps\"], progress_bar=False)\n","    #     agent.learn(total_timesteps=500, progress_bar=False)\n","\n","    pmf = get_policy_prob(\n","        agent,\n","        vae_get_pmf,\n","        n_states=env_kwargs[\"n_states\"],\n","        map_height=env_kwargs[\"map_height\"],\n","        cnn=True,\n","    )\n","\n","    score_room_1 = np.sum(pi[room_1_mask] * pmf[room_1_mask], axis=1).mean()\n","    score_room_2 = np.sum(pi[room_2_mask] * pmf[room_2_mask], axis=1).mean()\n","    score_room_3 = np.sum(pi[room_3_mask] * pmf[room_3_mask], axis=1).mean()\n","\n","    v = get_value_function(agent, task)\n","\n","    scores.append(\n","        pd.DataFrame(\n","            {\n","                \"Iteration\": [idx] * 4,\n","                \"Score\": [\n","                    np.sum(pi * pmf, axis=1).mean(),\n","                    score_room_1,\n","                    score_room_2,\n","                    score_room_3,\n","                ],\n","                \"Condition\": [\"Overall\", \"Room 1\", \"Room 2\", \"Room 3\"],\n","            }\n","        )\n","    )\n","\n","    value_functions.append(\n","        pd.DataFrame(\n","            {\n","                \"Iteration\": [idx] * task.n_states,\n","                \"State-Values\": v.reshape(-1),\n","                \"States\": np.arange(task.n_states),\n","            }\n","        )\n","    )\n","\n","scores = pd.concat(scores)\n","value_functions = pd.concat(value_functions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NY0NZDioCiXU"},"outputs":[],"source":["# Plot the average value function (n)\n","\n","# normalize the value function between zero and one within each iteration\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","def min_max_scale(grouped_data):\n","    v = grouped_data[\"State-Values\"].values.reshape(-1, 1)\n","    v = MinMaxScaler().fit_transform(grouped_data[\"State-Values\"].values.reshape(-1, 1))\n","    grouped_data[\"State-Values\"] = v\n","    return grouped_data.drop(\"Iteration\", axis=1)\n","\n","\n","normed_vf = value_functions.groupby(\"Iteration\", group_keys=True).apply(min_max_scale)\n","\n","# average and plot\n","plt.imshow(x.groupby(\"States\").mean().values.reshape(20, 20))\n","task.display_gridworld(plt.gca(), wall_color=\"w\", annotate=True)\n","plt.title(\"Learned Value function\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wj_z0BzYCiXU"},"outputs":[],"source":["# plot 1d Value function through the goal\n","normed_vf[\"Row\"] = normed_vf[\"States\"] // 20\n","normed_vf[\"Column\"] = normed_vf[\"States\"] % 20\n","\n","sns.relplot(\n","    data=normed_vf[normed_vf[\"Row\"] == 4], x=\"Column\", y=\"State-Values\", kind=\"line\"\n",")\n","sns.relplot(\n","    data=normed_vf[(normed_vf[\"Column\"] >= 9) & (normed_vf[\"Column\"] <= 10)],\n","    x=\"Row\",\n","    y=\"State-Values\",\n","    kind=\"line\",\n","    hue=\"Column\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"nLzKl0_kCiXU"},"source":["plt.imshow(\n","    value_functions.groupby(\"States\")[\"State-Values\"]\n","    .apply(np.nanmean)\n","    .values.reshape(20, 20)\n",")\n","value_functions.to_csv('value_functions_vae.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPepkS2fCiXU"},"outputs":[],"source":["sns.catplot(data=scores, y=\"Score\", x=\"Condition\", kind=\"bar\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hp9hNe3UCiXU"},"outputs":[],"source":["scores[\"Model\"] = \"Value Iteration\"\n","scores.to_csv(SAVE_FILE_NAME)\n","scores2 = pd.read_csv(\"sims_thread_the_needle.csv\")\n","scores2[\"Model\"] = \"PPO\"\n","scores3 = pd.read_csv(\"sims_thread_the_needle_state_inf.csv\")\n","scores3[\"Model\"] = \"Value Iteration + action based decoder\"\n","\n","\n","all_scores = pd.concat([scores, scores2, scores3])\n","sns.catplot(\n","    data=all_scores[all_scores[\"Condition\"] != \"Overall\"],\n","    y=\"Score\",\n","    x=\"Condition\",\n","    kind=\"point\",\n","    hue=\"Model\",\n",")\n","plt.gca().set_ylim([0, 1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ah_dtJRLCiXU"},"outputs":[],"source":["sns.catplot(\n","    data=all_scores[all_scores[\"Condition\"] == \"Overall\"],\n","    y=\"Score\",\n","    x=\"Model\",\n","    kind=\"bar\",\n",")\n","plt.gca().set_ylim([0, 1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtMee5jxCiXU"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1652455236434fd595f478f228333ade":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1d32540b92e4e4584ac3aa628436021","placeholder":"​","style":"IPY_MODEL_ce22fd1425e34878b5bf57a180e6b68a","value":"100%"}},"35db648b0ccf49a898f46c7002c182ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1652455236434fd595f478f228333ade","IPY_MODEL_971b821eb13d4257a7c2ae73381df11e","IPY_MODEL_b44689589e2b4f1dbb45f61c49d4062f"],"layout":"IPY_MODEL_60ad1b1ffe8c47518fb905de5a2ba43b"}},"3a6976f1e97e4bfa9c820ae22c022177":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"532462010a464a408a44e376dbbd6ec2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60ad1b1ffe8c47518fb905de5a2ba43b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"971b821eb13d4257a7c2ae73381df11e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_532462010a464a408a44e376dbbd6ec2","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f15532d5a2d84f078b135130546e00f9","value":1000}},"a8b47418ba51421396006975690322d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44689589e2b4f1dbb45f61c49d4062f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8b47418ba51421396006975690322d2","placeholder":"​","style":"IPY_MODEL_3a6976f1e97e4bfa9c820ae22c022177","value":" 1000/1000 [00:07&lt;00:00, 87.20it/s]"}},"ce22fd1425e34878b5bf57a180e6b68a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1d32540b92e4e4584ac3aa628436021":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f15532d5a2d84f078b135130546e00f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
