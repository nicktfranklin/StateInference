state_inference_model:
  batch_size: 64
  n_epochs: 20
  grad_clip: True
  optim_kwargs:
    lr: 0.0003

rnn_model_kwargs:
  batch_size: 64
  n_epochs: 20
  grad_clip: False
  optim_kwargs:
    lr: 0.0001
    weight_decay: 0.1
  max_sequence_len: 4

vae_kwargs:
  beta: 1.0
  tau: 2.0
  gamma: 0.99 

value_iteration_kwargs:
  gamma: 0.99
  n_iter: 1000
  softmax_gain: 1.0
  epsilon: 0.05
  batch_length: None

q_learning_kwargs:
  alpha: 0.05

