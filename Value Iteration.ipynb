{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f94262",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import environments.thread_the_needle as e\n",
    "import matplotlib.pyplot as plt\n",
    "import models.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from models import MCTS, GridWorldNode, ValueIterationNetwork\n",
    "from models.utils import softmax\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b6575",
   "metadata": {},
   "source": [
    "# Example 1: Diffusion (random transitions) with Rewards in corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa09c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9af99a800184e8088e87e8f26009fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'dia_matrix' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# call the value iteration network\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m Q, V \u001b[38;5;241m=\u001b[39m \u001b[43mValueIterationNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_iteration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransition_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msparse_diffusion_matrix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreward_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_interim_estimates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ValueIteration/models/value_iteration_network.py:120\u001b[0m, in \u001b[0;36mValueIterationNetwork.value_iteration\u001b[0;34m(transition_functions, reward_functions, n_rows, n_columns, gamma, iterations, initialization_noise, return_interim_estimates)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m tnrange(\u001b[38;5;241m0\u001b[39m, iterations):\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# calculate tiled values (we could randomize the tiling order but it isn't important)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a, (r_a, t_a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(reward_functions, transition_functions)):\n\u001b[0;32m--> 120\u001b[0m         q_0[a] \u001b[38;5;241m=\u001b[39m r_a[tiling] \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m \u001b[43mt_a\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtiling\u001b[49m\u001b[43m]\u001b[49m[:, \u001b[38;5;241m~\u001b[39mtiling]\u001b[38;5;241m.\u001b[39mdot(value_1)\n\u001b[1;32m    121\u001b[0m     value_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(q_0, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a, (r_a, t_a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(reward_functions, transition_functions)):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dia_matrix' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# define the enviornment\n",
    "n_rows, n_columns = 20, 20\n",
    "grid_shape = (n_rows, n_columns)\n",
    "\n",
    "sparse_diffusion_matrix =  e.make_diffision_transition_matrix(\n",
    "    n_rows, n_columns, sparse=True\n",
    ")\n",
    "\n",
    "R = np.ones(n_rows * n_columns) * 0\n",
    "R[0] = 1.0\n",
    "R[n_columns - 1] = 1.0\n",
    "R[-1] = 1.0\n",
    "R[-n_columns] = 1.0\n",
    "\n",
    "gamma = 0.8\n",
    "iterations = 10\n",
    "\n",
    "# call the value iteration network\n",
    "Q, V = ValueIterationNetwork.value_iteration(\n",
    "    transition_functions=[sparse_diffusion_matrix],\n",
    "    reward_functions=[R],\n",
    "    n_rows=n_rows,\n",
    "    n_columns=n_columns,\n",
    "    gamma=gamma,\n",
    "    iterations=iterations,\n",
    "    return_interim_estimates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.linalg.norm(V - np.tile(V[-1, :], (iterations, 1)), axis=1)\n",
    "plt.plot(np.arange(1, len(error)), error[1:] / np.max(error))\n",
    "plt.ylabel(\"Relative Error to final estimate\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(V[0, :].reshape(grid_shape), cmap=\"viridis\")\n",
    "plt.title(\"First value estimate\")\n",
    "# plt.savefig('images/2dDrift_v0.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Final value estimate\")\n",
    "plt.imshow(V[-1, :].reshape(grid_shape), cmap=\"viridis\", vmin=0, vmax=1)\n",
    "# plt.savefig('images/2dDrift_vf.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2edce",
   "metadata": {},
   "source": [
    "# Example 2: 1D Diffusion with Reward on one end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03823d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the enviornment\n",
    "n_rows, n_columns = 1, 20\n",
    "\n",
    "sparse_diffusion_matrix = e.make_diffision_transition_matrix(\n",
    "    n_rows, n_columns, sparse=True\n",
    ")\n",
    "\n",
    "R = np.ones(n_rows * n_columns) * 0\n",
    "R[0] = 1.0\n",
    "\n",
    "iterations = 10000\n",
    "\n",
    "# helper function\n",
    "def plot_1d_value_estimates(value_estimates, gamma, ax=None, legend=True):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    n_steps = 7\n",
    "    cc = sns.color_palette(\"viridis_r\", n_colors=n_steps)\n",
    "    for ii in range(0, n_steps):\n",
    "        ax.plot(value_estimates[2 ** ii, :], label=f\"{2**ii}\", c=cc[ii])\n",
    "    ax.plot(value_estimates[-1, :], label=f\"10,000\", c=\"k\", ls=\"--\")\n",
    "    ax.set_ylabel(\"Estimated Value\")\n",
    "    ax.set_xlabel(\"Distance from left edge\")\n",
    "    if legend:\n",
    "        ax.legend(title=\"Iteration\")\n",
    "    ax.set_title(r\"$\\gamma={}$\".format(gamma))\n",
    "    ax.set_xticks([ii for ii in range(0, n_columns + 1, 4)])\n",
    "\n",
    "\n",
    "#     sns.despine(trim=True)\n",
    "\n",
    "\n",
    "def value_estimate_error(value_estimates):\n",
    "    return np.linalg.norm(\n",
    "        value_estimates[:-1:] - np.tile(value_estimates[-1, :], (iterations - 1, 1)),\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.8\n",
    "\n",
    "# call the value iteration network\n",
    "Q, V_g80 = ValueIterationNetwork.value_iteration(\n",
    "    transition_functions=[sparse_diffusion_matrix],\n",
    "    reward_functions=[R],\n",
    "    n_rows=n_rows,\n",
    "    n_columns=n_columns,\n",
    "    gamma=gamma,\n",
    "    iterations=iterations,\n",
    "    return_interim_estimates=True,\n",
    ")\n",
    "\n",
    "error_g08 = value_estimate_error(V_g80)\n",
    "\n",
    "plot_1d_value_estimates(V_g80, gamma)\n",
    "# plt.savefig('images/1dDrift_g8.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.98\n",
    "\n",
    "# call the value iteration network\n",
    "Q, V_g98 = ValueIterationNetwork.value_iteration(\n",
    "    transition_functions=[sparse_diffusion_matrix],\n",
    "    reward_functions=[R],\n",
    "    n_rows=n_rows,\n",
    "    n_columns=n_columns,\n",
    "    gamma=gamma,\n",
    "    iterations=iterations,\n",
    "    return_interim_estimates=True,\n",
    ")\n",
    "\n",
    "error_g098 = value_estimate_error(V_g98)\n",
    "\n",
    "plot_1d_value_estimates(V_g98, gamma)\n",
    "# plt.savefig('images/1dDrift_g98.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3), sharey=False)\n",
    "plot_1d_value_estimates(V_g80, 0.80, ax=axes[0], legend=False)\n",
    "plot_1d_value_estimates(V_g98, 0.98, ax=axes[1], legend=True)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"images/1D-statespace.pdf\", dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0afbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.999\n",
    "\n",
    "# call the value iteration network\n",
    "Q, V = ValueIterationNetwork.value_iteration(\n",
    "    transition_functions=[sparse_diffusion_matrix],\n",
    "    reward_functions=[R],\n",
    "    n_rows=n_rows,\n",
    "    n_columns=n_columns,\n",
    "    gamma=gamma,\n",
    "    iterations=iterations,\n",
    "    return_interim_estimates=True,\n",
    ")\n",
    "\n",
    "error_g0999 = value_estimate_error(V)\n",
    "\n",
    "plot_1d_value_estimates(V, gamma)\n",
    "# plt.savefig('images/1dDrift_g999.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error_g08/np.max(error_g08), label=r'$\\gamma = {}$'.format(0.8))\n",
    "plt.plot(error_g098/np.max(error_g098), label=r'$\\gamma = {}$'.format(0.98))\n",
    "plt.plot(error_g0999/np.max(error_g0999), label=r'$\\gamma = {}$'.format(0.99))\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Itterations')\n",
    "plt.ylabel('Relative Error of Value function')\n",
    "sns.despine(trim=True)\n",
    "plt.savefig('images/convergence_as_function_of_gamma.pdf', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = simulation_utils.evaluate_policy(mcts.get_selection_policy(beta=4), optimal_policy)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# pos  = ax.imshow(error.reshape(1, -1), cmap=sns.color_palette(\"Blues\", as_cmap=True), vmin=0, vmax=1)\n",
    "# plt.plot(5, 0, '*', c='r', markersize=8)\n",
    "# environments.clean_up_reward_at_end(plt.gca(), n_columns)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e5e20",
   "metadata": {},
   "source": [
    "## Visualization: Adjacency Matrix\n",
    "2-d lattice grid-world with 16 states\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c981acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_rows, n_columns = 5, 6\n",
    "transition_functions = e.make_diffision_transition_matrix(n_rows, n_columns, False)\n",
    "\n",
    "#conver to adjacency matrix\n",
    "import matplotlib\n",
    "transition_functions = transition_functions > 1e-3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.imshow(transition_functions, cmap=matplotlib.colors.ListedColormap(['White'] + sns.color_palette(\"Blues\")),vmin=0)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "fig.savefig('images/5x6adjacency.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d1d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fda82563",
   "metadata": {},
   "source": [
    "## Example 4: Needle in a Haystack\n",
    "This is designed as an example that is difficult for MCTS but easy for Value iteration. Note: these are the first simulations to derive a meaningful policy (the above were diffusion policies).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the enviornment\n",
    "n_rows, n_columns = 20, 20\n",
    "movement_penalty = 0\n",
    "slip_probability = 0.05\n",
    "random_movement_on_error = False\n",
    "\n",
    "transition_functions, state_reward_function, optimal_policy = e.make_thread_the_needle(\n",
    "    n_rows=n_rows,\n",
    "    n_columns=n_columns,\n",
    "    movement_penalty=movement_penalty,\n",
    "    slip_probability=slip_probability,\n",
    "    random_movement_on_error=random_movement_on_error\n",
    ")\n",
    "\n",
    "\n",
    "state_action_reward_functions = e.get_state_action_reward_from_sucessor_rewards(\n",
    "    state_reward_function, transition_functions\n",
    ")\n",
    "\n",
    "\n",
    "grid_shape = (n_rows, n_columns)\n",
    "\n",
    "goal_state = 0\n",
    "bottleneck_start_state = n_rows * n_columns - n_columns//2 \n",
    "corner_start_state = n_rows * n_columns - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.zeros((n_rows, n_columns)), cmap='Greys')\n",
    "e.clean_up_thread_the_needle_plot(plt.gca(), n_columns, n_rows)\n",
    "\n",
    "plt.gca().annotate('G', (0, 0), ha='center', va='center', c='k')\n",
    "plt.gca().annotate('S', (n_rows-5, n_columns-6), ha='center', va='center', c='k')\n",
    "plt.title('Thread-the-needle task')\n",
    "plt.savefig('images/thread_the_needle_task.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc47c5",
   "metadata": {},
   "source": [
    "### Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "beta = 5\n",
    "\n",
    "common_model_kwargs = dict(\n",
    "    transition_functions=transition_functions, \n",
    "    reward_functions=state_action_reward_functions,\n",
    "    n_rows=n_rows, \n",
    "    n_columns=n_columns\n",
    ")\n",
    "\n",
    "\n",
    "fig_v, axes_v = plt.subplots(1, 4, figsize=(20, 5))\n",
    "fig_e, axes_e = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "\n",
    "\n",
    "# 1 iteration\n",
    "def evalute_plot_vi(iterations, ax_v, ax_e):\n",
    "    Q, R = ValueIterationNetwork.value_iteration(gamma=gamma, **common_model_kwargs, iterations=iterations)\n",
    "    pi = softmax(Q, beta=beta)\n",
    "    error = models.utils.evaluate_policy(pi, optimal_policy=optimal_policy)\n",
    "\n",
    "    ax_v.imshow(R.reshape(n_rows, n_columns) )\n",
    "    \n",
    "    r, c = e.get_position_from_state(bottleneck_start_state, n_columns)\n",
    "    ax_v.plot(c, r, '*', c='r', markersize=8)\n",
    "    e.clean_up_thread_the_needle_plot(ax_v, n_columns, n_rows)\n",
    "    ax_v.set_title(f\"{iterations} Iterations\")\n",
    "\n",
    "    pos  = ax_e.imshow(error.reshape(grid_shape), \n",
    "                     cmap=sns.color_palette(\"Blues\", as_cmap=True), vmin=0, vmax=1)\n",
    "    e.clean_up_thread_the_needle_plot(ax_e, n_columns, n_rows)\n",
    "    ax_e.set_title(f\"{iterations} Iterations\")\n",
    "    \n",
    "evalute_plot_vi(4, axes_v[0], axes_e[0])\n",
    "evalute_plot_vi(8, axes_v[1], axes_e[1])\n",
    "evalute_plot_vi(16, axes_v[2], axes_e[2])\n",
    "evalute_plot_vi(24, axes_v[3], axes_e[3])\n",
    "\n",
    "fig_v.suptitle('Value Function Estimates')\n",
    "fig_e.suptitle('Policy Error')\n",
    "\n",
    "fig_v.savefig('images/thread_the_needle_value_function.png', dpi=300)\n",
    "fig_e.savefig('images/thread_the_needle_policy_error.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
